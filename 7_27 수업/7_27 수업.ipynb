{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T01:37:16.125321Z",
     "start_time": "2020-07-27T01:37:15.156253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               699 non-null    int64 \n",
      " 1   clump            699 non-null    int64 \n",
      " 2   cell_size        699 non-null    int64 \n",
      " 3   cell_shape       699 non-null    int64 \n",
      " 4   adhesion         699 non-null    int64 \n",
      " 5   epithlial        699 non-null    int64 \n",
      " 6   bare_nuclei      699 non-null    object\n",
      " 7   chromatin        699 non-null    int64 \n",
      " 8   normal_nucleoli  699 non-null    int64 \n",
      " 9   mitoses          699 non-null    int64 \n",
      " 10  class            699 non-null    int64 \n",
      "dtypes: int64(10), object(1)\n",
      "memory usage: 60.2+ KB\n",
      "None\n",
      "\n",
      "\n",
      "                 id       clump   cell_size  cell_shape    adhesion  \\\n",
      "count  6.990000e+02  699.000000  699.000000  699.000000  699.000000   \n",
      "mean   1.071704e+06    4.417740    3.134478    3.207439    2.806867   \n",
      "std    6.170957e+05    2.815741    3.051459    2.971913    2.855379   \n",
      "min    6.163400e+04    1.000000    1.000000    1.000000    1.000000   \n",
      "25%    8.706885e+05    2.000000    1.000000    1.000000    1.000000   \n",
      "50%    1.171710e+06    4.000000    1.000000    1.000000    1.000000   \n",
      "75%    1.238298e+06    6.000000    5.000000    5.000000    4.000000   \n",
      "max    1.345435e+07   10.000000   10.000000   10.000000   10.000000   \n",
      "\n",
      "        epithlial   chromatin  normal_nucleoli     mitoses       class  \n",
      "count  699.000000  699.000000       699.000000  699.000000  699.000000  \n",
      "mean     3.216023    3.437768         2.866953    1.589413    2.689557  \n",
      "std      2.214300    2.438364         3.053634    1.715078    0.951273  \n",
      "min      1.000000    1.000000         1.000000    1.000000    2.000000  \n",
      "25%      2.000000    2.000000         1.000000    1.000000    2.000000  \n",
      "50%      2.000000    3.000000         1.000000    1.000000    2.000000  \n",
      "75%      4.000000    5.000000         4.000000    1.000000    4.000000  \n",
      "max     10.000000   10.000000        10.000000   10.000000    4.000000  \n",
      "\n",
      "\n",
      "['1' '10' '2' '4' '3' '9' '7' '?' '5' '8' '6']\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 683 entries, 0 to 698\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype\n",
      "---  ------           --------------  -----\n",
      " 0   id               683 non-null    int64\n",
      " 1   clump            683 non-null    int64\n",
      " 2   cell_size        683 non-null    int64\n",
      " 3   cell_shape       683 non-null    int64\n",
      " 4   adhesion         683 non-null    int64\n",
      " 5   epithlial        683 non-null    int64\n",
      " 6   bare_nuclei      683 non-null    int32\n",
      " 7   chromatin        683 non-null    int64\n",
      " 8   normal_nucleoli  683 non-null    int64\n",
      " 9   mitoses          683 non-null    int64\n",
      " 10  class            683 non-null    int64\n",
      "dtypes: int32(1), int64(10)\n",
      "memory usage: 61.4 KB\n",
      "None\n",
      "\n",
      "\n",
      "train data 개수:  (478, 9)\n",
      "test data 개수:  (205, 9)\n",
      "\n",
      "\n",
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "\n",
      "\n",
      "[[127   4]\n",
      " [  2  72]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.98       131\n",
      "           4       0.95      0.97      0.96        74\n",
      "\n",
      "    accuracy                           0.97       205\n",
      "   macro avg       0.97      0.97      0.97       205\n",
      "weighted avg       0.97      0.97      0.97       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# 기본 라이브러리 불러오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 1] 데이터 준비/ 기본 설정\n",
    "\n",
    "'''\n",
    "\n",
    "# Breast Cancer 데이터셋 가져오기 (출처: UCI ML Repository)\n",
    "uci_path = 'https://archive.ics.uci.edu/ml/machine-learning-databases/\\\n",
    "breast-cancer-wisconsin/breast-cancer-wisconsin.data'\n",
    "df = pd.read_csv(uci_path, header=None)\n",
    "\n",
    "\n",
    "# 열 이름 지정\n",
    "df.columns = ['id', 'clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "              'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses', 'class']\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 2] 데이터 탐색\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# 데이터 살펴보기\n",
    "df.head()\n",
    "\n",
    "\n",
    "# 데이터 자료형 확인\n",
    "print(df.info())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 데이터 통계 요약정보 확인\n",
    "print(df.describe())\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# bare_nuclei 열의 자료형 변경 (문자열 ->숫자)\n",
    "# bare_nuclei 열의 고유값 확인\n",
    "print(df['bare_nuclei'].unique())\n",
    "print('\\n')\n",
    "\n",
    "df['bare_nuclei'].replace('?', np.nan, inplace=True)      # '?'을 np.nan으로 변경\n",
    "df.dropna(subset=['bare_nuclei'], axis=0, inplace=True)   # 누락데이터 행을 삭제\n",
    "df['bare_nuclei'] = df['bare_nuclei'].astype('int')       # 문자열을 정수형으로 변환\n",
    "\n",
    "print(df.info())                                      # 데이터 통계 요약정보 확인\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "\n",
    "'''\n",
    "# id 컬럼은 필요없으므로 제외시키고 다른 훈련할 때 필요한 컬럼들을 선별힌다.\n",
    "# 속성(변수) 선택\n",
    "X = df[['clump', 'cell_size', 'cell_shape', 'adhesion', 'epithlial',\n",
    "        'bare_nuclei', 'chromatin', 'normal_nucleoli', 'mitoses']]  # 설명 변수 X\n",
    "y = df['class']  # 예측 변수 Y\n",
    "\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "pd.DataFrame(X).describe()\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)      # 2: benign(양성), 4: malignant(악성)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제230. class 를 value_count 하여 각각 건수가 어떻게 되는지 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T01:24:33.534584Z",
     "start_time": "2020-07-27T01:24:33.526589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    444\n",
       "4    239\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제231.  위의 의사결정트리 모델을 아산병원에서 사용할 수 있도록 FN을 0으로 만드는 max_depth를 알아내시오\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T01:39:46.740939Z",
     "start_time": "2020-07-27T01:39:46.721951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수:  (478, 9)\n",
      "test data 개수:  (205, 9)\n",
      "\n",
      "\n",
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "[4 4 4 4 4 4 2 2 4 4]\n",
      "\n",
      "\n",
      "[[126   5]\n",
      " [  0  74]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      0.96      0.98       131\n",
      "           4       0.94      1.00      0.97        74\n",
      "\n",
      "    accuracy                           0.98       205\n",
      "   macro avg       0.97      0.98      0.97       205\n",
      "weighted avg       0.98      0.98      0.98       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류)\n",
    "y_hat = tree_model.predict(X_test)      # 2: benign(양성), 4: malignant(악성)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics\n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)\n",
    "print(tree_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제232. seaborn의 타이타닉 데이터를 이용해서 의사결정트리 모델을 만들고 테스트 데이터의 정확도를 확인하시오\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T02:30:43.714923Z",
     "start_time": "2020-07-27T02:30:43.624978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n",
      "train data 개수:  (623, 9)\n",
      "test data 개수:  (268, 9)\n",
      "\n",
      "\n",
      "[0 0 0 1 1 0 0 0 0 0]\n",
      "[0 0 0 1 1 0 0 0 1 0]\n",
      "\n",
      "\n",
      "[[153  21]\n",
      " [ 22  72]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88       174\n",
      "           1       0.77      0.77      0.77        94\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.82      0.82      0.82       268\n",
      "weighted avg       0.84      0.84      0.84       268\n",
      "\n",
      "0.8395522388059702\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tt = sns.load_dataset('titanic')\n",
    "\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "rdf = tt.drop(['deck', 'embark_town'], axis=1)\n",
    "\n",
    "freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "rdf['age'].fillna(freq, inplace=True)\n",
    "\n",
    "\n",
    "ndf = rdf[['survived', 'pclass', 'sex', 'age','sibsp', 'parch', 'embarked']]\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, gender], axis=1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
    "onehot_embarked\n",
    "\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
    "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 2] 데이터 탐색\n",
    "\n",
    "'''\n",
    "\n",
    "tt.info() \n",
    "tt.describe()\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 3] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "X = ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male', 'town_C', 'town_Q', 'town_S']]\n",
    "y = ndf['survived']\n",
    "\n",
    "\n",
    "# 설명 변수 데이터를 정규화\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "pd.DataFrame(x).describe()\n",
    "\n",
    "# train data 와 test data로 구분(7:3 비율)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
    "\n",
    "print('train data 개수: ', X_train.shape)\n",
    "print('test data 개수: ', X_test.shape)\n",
    "print('\\n')\n",
    "\n",
    "'''\n",
    "\n",
    "[Step 4] Decision Tree 분류 모형 - sklearn 사용\n",
    "\n",
    "'''\n",
    "\n",
    "# sklearn 라이브러리에서 Decision Tree 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "\n",
    "# train data를 가지고 모형 학습\n",
    "tree_model.fit(X_train, y_train)   \n",
    "\n",
    "\n",
    "# test data를 가지고 y_hat을 예측 (분류) \n",
    "y_hat = tree_model.predict(X_test)      # 2: benign(양성), 4: malignant(악성)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - Confusion Matrix 계산\n",
    "from sklearn import metrics \n",
    "tree_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
    "print(tree_matrix)\n",
    "print('\\n')\n",
    "\n",
    "# 모형 성능 평가 - 평가지표 계산\n",
    "tree_report = metrics.classification_report(y_test, y_hat)            \n",
    "print(tree_report)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 선생님 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T02:26:36.134449Z",
     "start_time": "2020-07-27T02:26:36.080483Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109  17]\n",
      " [ 22  67]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       126\n",
      "           1       0.80      0.75      0.77        89\n",
      "\n",
      "    accuracy                           0.82       215\n",
      "   macro avg       0.81      0.81      0.81       215\n",
      "weighted avg       0.82      0.82      0.82       215\n",
      "\n",
      "0.8186046511627907\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns',15)\n",
    "\n",
    "\n",
    "\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "mask4 = (df.age<10) | (df.sex=='female') \n",
    "\n",
    "df['child_women']=mask4.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "#        embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf = df.drop(['deck','embark_town'], axis =1)\n",
    "\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "rdf = rdf.dropna( subset=['age'], how='any', axis=0)\n",
    "\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['embarked'].value_counts().idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked','child_women']]\n",
    "\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis= 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'])\n",
    "\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1)\n",
    "\n",
    "ndf.drop(['sex','embarked'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "\n",
    "x = ndf[ ['pclass', 'age' ,'sibsp', 'parch' ,'female' ,'male', 'C' ,'Q' ,'S',    'child_women'] ]\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "\n",
    "# 5단계 훈련 데이터를 훈련 데이터 / 테스트 데이터로 나눈다\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,\n",
    "\n",
    "                                                 random_state = 33)\n",
    "\n",
    "# sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "# 모형 객체 생성 (criterion='entropy' 적용)\n",
    "tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "tree_model.fit( X_train, y_train )\n",
    "\n",
    "# 7단계 테스트 데이터로 예측을 한다.\n",
    "y_hat = tree_model.predict( X_test )\n",
    "\n",
    "\n",
    "# 8단계 모형의 예측능력을 평가한다.\n",
    "\n",
    "from sklearn import metrics\n",
    "randomforest_matrix = metrics.confusion_matrix( y_test, y_hat )\n",
    "print( randomforest_matrix )\n",
    "\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "f1_report = metrics.classification_report( y_test, y_hat )\n",
    "print( f1_report )\n",
    "\n",
    "#print(np.array([[tp,fp],[fn,tn]]))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문제233. for loop 문을 이용해서 정확도가 높은 max_depth가 무엇인지 알아내시오\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T03:08:39.203081Z",
     "start_time": "2020-07-27T03:08:21.708872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state:  1 max_depth:  1 accuracy:  0.75\n",
      "random_state:  1 max_depth:  2 accuracy:  0.753731343283582\n",
      "random_state:  1 max_depth:  3 accuracy:  0.7723880597014925\n",
      "random_state:  1 max_depth:  4 accuracy:  0.7835820895522388\n",
      "random_state:  2 max_depth:  3 accuracy:  0.8022388059701493\n",
      "random_state:  3 max_depth:  3 accuracy:  0.8097014925373134\n",
      "random_state:  4 max_depth:  1 accuracy:  0.8208955223880597\n",
      "random_state:  4 max_depth:  2 accuracy:  0.8395522388059702\n",
      "random_state:  5 max_depth:  4 accuracy:  0.8470149253731343\n",
      "random_state:  6 max_depth:  3 accuracy:  0.8507462686567164\n",
      "random_state:  33 max_depth:  4 accuracy:  0.8582089552238806\n",
      "random_state:  33 max_depth:  5 accuracy:  0.8694029850746269\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "\n",
    "# 컬럼이 모두다 출력될 수 있도록 출력할 열의 개수 한도를 늘리기\n",
    "pd.set_option('display.max_columns',15)\n",
    "\n",
    "\n",
    "\n",
    "# 2단계 결측치 확인하고 제거하거나 치환한다.\n",
    "\n",
    "# 2.1 타이타닉 데이터 프레임의 자료형을 확인한다.\n",
    "\n",
    "mask4 = (df.age<10) | (df.sex=='female') \n",
    "\n",
    "df['child_women']=mask4.astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "#        embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf = df.drop(['deck','embark_town'], axis =1)\n",
    "\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "freq = rdf['age'].value_counts(dropna=True).idxmax()\n",
    "rdf['age'].fillna(freq, inplace=True)\n",
    "\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['embarked'].value_counts().idxmax()\n",
    "rdf['embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked','child_women']]\n",
    "\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "gender = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf,gender], axis= 1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'])\n",
    "\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1)\n",
    "\n",
    "ndf.drop(['sex','embarked'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "\n",
    "x = ndf[ ['pclass', 'age' ,'sibsp', 'parch' ,'female', 'male', 'C' ,'Q' ,'S',    'child_women'] ]\n",
    "y = ndf['survived'] # 종속변수\n",
    "\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "\n",
    "max = 0\n",
    "for i in range(1,50) :\n",
    "#     print('random_state:', i)\n",
    "    # 5단계 훈련 데이터를 훈련 데이터 / 테스트 데이터로 나눈다\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3,\n",
    "\n",
    "                                                     random_state = i)\n",
    "\n",
    "    # sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\n",
    "    from sklearn import tree\n",
    "    for k in range(1,50) :\n",
    "#         print('max_depth: ', k)\n",
    "        # 모형 객체 생성 (criterion='entropy' 적용)\n",
    "        tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=k)\n",
    "        tree_model.fit( X_train, y_train )\n",
    "\n",
    "        # 7단계 테스트 데이터로 예측을 한다.\n",
    "        y_hat = tree_model.predict( X_test )\n",
    "\n",
    "\n",
    "        # 8단계 모형의 예측능력을 평가한다.\n",
    "\n",
    "        from sklearn import metrics\n",
    "        randomforest_matrix = metrics.confusion_matrix( y_test, y_hat )\n",
    "#         print( randomforest_matrix )\n",
    "\n",
    "\n",
    "        tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel()\n",
    "\n",
    "        f1_report = metrics.classification_report( y_test, y_hat )\n",
    "    #     print( f1_report )\n",
    "\n",
    "        #print(np.array([[tp,fp],[fn,tn]]))\n",
    "\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        accuracy = accuracy_score( y_test, y_hat)\n",
    "        \n",
    "        if accuracy > max :\n",
    "            max = accuracy\n",
    "            print('random_state: ', i, 'max_depth: ', k, 'accuracy: ', accuracy)\n",
    "#         print(accuracy, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 점심시간 문제\n",
    "#### 문제 234. 카페에 올린 for loop문 스크립트를 이용해서 정확도가 가장 좋은 random_state와 max_depth를 알아내시오\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T03:09:01.567308Z",
     "start_time": "2020-07-27T03:08:54.156880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8694029850746269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "b=[]\n",
    "c=[]\n",
    "\n",
    "for i  in  range(1, 50):\n",
    "    X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.3, random_state = i)\n",
    "\n",
    "    # sklearn 라이브러리에서 나이브베이즈 분류 모형 가져오기\n",
    "    # 모형 객체 생성 (criterion='entropy' 적용)\n",
    "\n",
    "    for  k  in  range(1,50):\n",
    "        b.append((i,k))\n",
    "        tree_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=k)\n",
    "        tree_model.fit( X_train, y_train )\n",
    "\n",
    "        # 7단계 테스트 데이터로 예측을 한다.\n",
    "        y_hat = tree_model.predict( X_test )\n",
    "\n",
    "        # 8단계 모형의 예측능력을 평가한다.\n",
    "        randomforest_matrix = metrics.confusion_matrix( y_test, y_hat )\n",
    "        accuracy = accuracy_score( y_test, y_hat)\n",
    "        c.append(accuracy)\n",
    "\n",
    "# print(np.max(c))\n",
    "\n",
    "idx = c.index(np.max(c))\n",
    "print('random_state: ', b[idx][0], 'max_depth: ', b[idx][1], 'accuracy:', c[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T03:10:52.463879Z",
     "start_time": "2020-07-27T03:10:52.458882Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state: 33 \tmax_depth: 5 \taccuracy: 0.8694029850746269\n"
     ]
    }
   ],
   "source": [
    "print('random_state:', b[idx][0], '\\tmax_depth:', b[idx][1], '\\taccuracy:', c[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
