{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T11:20:26.849366Z",
     "start_time": "2020-08-02T11:20:23.245563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero-Fares: 0\n",
      "Cross validation score: 0.785\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 1 0 0 0]\n",
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load and display train dataa\n",
    "train_data = pd.read_csv('D:/Desktop/Itwill ws/pandas_ml/train.csv')\n",
    "test_data = pd.read_csv(\"D:/Desktop/Itwill ws/pandas_ml/test.csv\")\n",
    "train_data.head()\n",
    "\n",
    "def remove_zero_fares(row):\n",
    "    if row.Fare == 0:\n",
    "        row.Fare = np.NaN\n",
    "    return row\n",
    "# Apply the function\n",
    "train_data = train_data.apply(remove_zero_fares, axis=1)\n",
    "test_data = test_data.apply(remove_zero_fares, axis=1)\n",
    "# Check if it did the job\n",
    "print('Number of zero-Fares: {:d}'.format(train_data.loc[train_data.Fare==0].shape[0]))\n",
    "\n",
    "train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "test_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "train_data['Title'].value_counts()\n",
    "test_data['Title'].value_counts()\n",
    "\n",
    "# Substitute rare female titles\n",
    "train_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n",
    "test_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n",
    "\n",
    "# Substitute rare male titles\n",
    "train_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\n",
    "test_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\n",
    "\n",
    "# Extract the first two letters\n",
    "train_data['Ticket_lett'] = train_data.Ticket.apply(lambda x: x[:2])\n",
    "test_data['Ticket_lett'] = test_data.Ticket.apply(lambda x: x[:2])\n",
    "\n",
    "# Calculate ticket length\n",
    "train_data['Ticket_len'] = train_data.Ticket.apply(lambda x: len(x))\n",
    "test_data['Ticket_len'] = test_data.Ticket.apply(lambda x: len(x))\n",
    "\n",
    "# Creation of a new Fam_size column\n",
    "train_data['Fam_size'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['Fam_size'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "# Creation of four groups\n",
    "train_data['Fam_type'] = pd.cut(train_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "test_data['Fam_type'] = pd.cut(test_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "\n",
    "# Creation of Last name\n",
    "train_data['Family'] = train_data.Name.str.split('.').str.get(1).str.split(' ').str.get(1)\n",
    "test_data['Family'] = test_data.Name.str.split('.').str.get(1).str.split(' ').str.get(1)\n",
    "\n",
    "# Creation of Name size\n",
    "train_data['Name_size'] = train_data.Name.str.split('.').str.get(1).apply(lambda x: len(x))\n",
    "test_data['Name_size'] = test_data.Name.str.split('.').str.get(1).apply(lambda x: len(x))\n",
    "\n",
    "cut = [0,15,30,40,60]\n",
    "# [0,10,25,40,60]\n",
    "\n",
    "train_data['Name_type'] = pd.cut(train_data.Name_size,cut, labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "test_data['Name_type'] = pd.cut(test_data.Name_size, cut , labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "\n",
    "\n",
    "y = train_data['Survived']\n",
    "features = ['Pclass', 'Fare', 'Title', 'Embarked', 'Fam_type', 'Ticket_len',\n",
    "            'Ticket_lett','Family','Name_type']\n",
    "X = train_data[features]\n",
    "X.head()\n",
    "\n",
    "numerical_cols = ['Fare']\n",
    "categorical_cols = ['Pclass', 'Title', 'Embarked', 'Fam_type', 'Ticket_len',\n",
    "                    'Ticket_lett','Family','Name_type']\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Bundle preprocessing and modeling code \n",
    "titanic_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                   ('model', RandomForestClassifier(random_state=0, n_estimators=500, max_depth=5))\n",
    "                                  ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "titanic_pipeline.fit(X,y)\n",
    "\n",
    "print('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))\n",
    "\n",
    "X_test = test_data[features]\n",
    "X_test.head()\n",
    "\n",
    "# Preprocessing of test data, get predictions\n",
    "predictions = titanic_pipeline.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('D:/Desktop/Itwill ws/pandas_ml/my_submission.csv', index=False)\n",
    "print('Your submission was successfully saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load and display train data\n",
    "train_data = pd.read_csv('D:/Desktop/Itwill ws/pandas_ml/train.csv')\n",
    "test_data = pd.read_csv(\"D:/Desktop/Itwill ws/pandas_ml/test.csv\")\n",
    "train_data.head()\n",
    "\n",
    "def remove_zero_fares(row):\n",
    "    if row.Fare == 0:\n",
    "        row.Fare = np.NaN\n",
    "    return row\n",
    "# Apply the function\n",
    "train_data = train_data.apply(remove_zero_fares, axis=1)\n",
    "test_data = test_data.apply(remove_zero_fares, axis=1)\n",
    "# Check if it did the job\n",
    "print('Number of zero-Fares: {:d}'.format(train_data.loc[train_data.Fare==0].shape[0]))\n",
    "\n",
    "train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "test_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "train_data['Title'].value_counts()\n",
    "test_data['Title'].value_counts()\n",
    "\n",
    "train_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n",
    "test_data['Title'].replace(['Mme', 'Ms', 'Lady', 'Mlle', 'the Countess', 'Dona'], 'Miss', inplace=True)\n",
    "\n",
    "train_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\n",
    "test_data['Title'].replace(['Major', 'Col', 'Capt', 'Don', 'Sir', 'Jonkheer'], 'Mr', inplace=True)\n",
    "\n",
    "train_data['Ticket_lett'] = train_data.Ticket.apply(lambda x: x[:2])\n",
    "test_data['Ticket_lett'] = test_data.Ticket.apply(lambda x: x[:2])\n",
    "\n",
    "# Calculate ticket length\n",
    "train_data['Ticket_len'] = train_data.Ticket.apply(lambda x: len(x))\n",
    "test_data['Ticket_len'] = test_data.Ticket.apply(lambda x: len(x))\n",
    "\n",
    "# Creation of a new Fam_size column\n",
    "train_data['Fam_size'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['Fam_size'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "# Creation of four groups\n",
    "train_data['Fam_type'] = pd.cut(train_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "test_data['Fam_type'] = pd.cut(test_data.Fam_size, [0,1,4,7,11], labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "\n",
    "# Creation of Last name\n",
    "train_data['Family'] = train_data.Name.str.split('.').str.get(1).str.split(' ').str.get(1)\n",
    "test_data['Family'] = test_data.Name.str.split('.').str.get(1).str.split(' ').str.get(1)\n",
    "\n",
    "# Creation of Name size\n",
    "train_data['Name_size'] = train_data.Name.str.split('.').str.get(1).apply(lambda x: len(x))\n",
    "test_data['Name_size'] = test_data.Name.str.split('.').str.get(1).apply(lambda x: len(x))\n",
    "\n",
    "cut = [0,10,25,40,60]\n",
    "# [0,10,25,40,60]\n",
    "train_data['Name_type'] = pd.cut(train_data.Name_size,[0,10,25,40,60], labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "test_data['Name_type'] = pd.cut(test_data.Name_size,[0,10,25,40,60], labels=['Solo', 'Small', 'Big', 'Very big'])\n",
    "\n",
    "y = train_data['Survived']\n",
    "features = ['Pclass', 'Fare', 'Title', 'Embarked', 'Fam_type', 'Ticket_len',\n",
    "            'Ticket_lett','Family','Name_type']\n",
    "X = train_data[features]\n",
    "X.head()\n",
    "\n",
    "numerical_cols = ['Fare']\n",
    "categorical_cols = ['Pclass', 'Title', 'Embarked', 'Fam_type', 'Ticket_len',\n",
    "                    'Ticket_lett','Family','Name_type']\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Bundle preprocessing and modeling code \n",
    "titanic_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                   ('model', RandomForestClassifier(random_state=0, n_estimators=500, max_depth=5))\n",
    "                                  ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "titanic_pipeline.fit(X,y)\n",
    "\n",
    "print('Cross validation score: {:.3f}'.format(cross_val_score(titanic_pipeline, X, y, cv=10).mean()))\n",
    "\n",
    "X_test = test_data[features]\n",
    "X_test.head()\n",
    "\n",
    "# Preprocessing of test data, get predictions\n",
    "predictions = titanic_pipeline.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('c:/data/my_submission.csv', index=False)\n",
    "print('Your submission was successfully saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
