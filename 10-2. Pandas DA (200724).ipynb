{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>■ 파이썬으로 머신러닝 구현하기</b>\n",
    "    1. kNN 알고리즘\n",
    "    2. naiveBayes 알고리즘\n",
    "    \n",
    "### <b>■ naiveBayes 알고리즘으로 타이타닉 생존자 예측</b>\n",
    "    sklearn 모델 생성 문법\n",
    "```python\n",
    "from sklearn import BernoullinB\n",
    "model = BernoulliNB(alpha=0.4)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T05:31:12.663157Z",
     "start_time": "2020-07-24T05:31:12.604191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[153  25]\n",
      " [ 28  62]]\n",
      "0.8022388059701493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.85       178\n",
      "           1       0.71      0.69      0.70        90\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.78      0.77      0.78       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제. 타이타닉 나이브베이즈 모델 생성 예제\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "n_df = pd.read_csv('train.csv')\n",
    "df = pd.concat([df,n_df['Name']],axis=1)\n",
    "appel = df['Name'].str.split(',').str[1].str.split('.')\n",
    "df['title'] = appel.str.get(0)\n",
    "\n",
    "# age_m = pd.DataFrame(round(df.groupby('title')['age'].mean(),1))\n",
    "# df = pd.merge(df, age_m, on='title',how='left')\n",
    "\n",
    "rdf = df.drop(['embark_town','deck'],axis=1)\n",
    "rdf\n",
    "\n",
    "rdf['age'].fillna(rdf['age'].value_counts(dropna=True).idxmax(), inplace=True) # 최빈값으로 치환\n",
    "rdf['embarked'].fillna(rdf['embarked'].value_counts(dropna=True).idxmax() , inplace=True ) \n",
    "\n",
    "rdf.columns.values\n",
    "\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked']]\n",
    "\n",
    "gender = pd.get_dummies(ndf.sex)\n",
    "ndf = pd.concat([ndf, gender],axis=1)\n",
    "\n",
    "oh_embarked = pd.get_dummies(ndf.embarked, prefix='town')\n",
    "ndf = pd.concat([ndf, oh_embarked], axis=1)\n",
    "ndf = ndf.drop(['embarked','sex'],axis=1,)\n",
    "\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S']]\n",
    "y = ndf.survived\n",
    "\n",
    "from sklearn import preprocessing as ppc\n",
    "X = ppc.StandardScaler().fit(X).transform(X)\n",
    "X\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# 모델 훈련\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "naive_m = BernoulliNB(alpha=0.3)\n",
    "naive_m.fit(X_train, y_train)\n",
    "\n",
    "y_hat = naive_m.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "naive_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(naive_matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제226. 여자와 아이 우선이라는 기준하에 파생변수를 추가해서 정확도가 더 올라가는지 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T05:39:19.288207Z",
     "start_time": "2020-07-24T05:39:19.223248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[157  21]\n",
      " [ 25  65]]\n",
      "0.8283582089552238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       178\n",
      "           1       0.76      0.72      0.74        90\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.81      0.80      0.81       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 예제. 타이타닉 나이브베이즈 모델 생성 예제\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "n_df = pd.read_csv('train.csv')\n",
    "df = pd.concat([df,n_df['Name']],axis=1)\n",
    "appel = df['Name'].str.split(',').str[1].str.split('.')\n",
    "df['title'] = appel.str.get(0)\n",
    "\n",
    "# age_m = pd.DataFrame(round(df.groupby('title')['age'].mean(),1))\n",
    "# df = pd.merge(df, age_m, on='title',how='left')\n",
    "\n",
    "rdf = df.drop(['embark_town','deck'],axis=1)\n",
    "rdf\n",
    "\n",
    "rdf['age'].fillna(rdf['age'].value_counts(dropna=True).idxmax(), inplace=True) # 최빈값으로 치환\n",
    "rdf['embarked'].fillna(rdf['embarked'].value_counts(dropna=True).idxmax() , inplace=True ) \n",
    "\n",
    "mask = (rdf.age<10) | (rdf.sex == 'female')\n",
    "rdf['women_child'] = mask.astype(int)\n",
    "\n",
    "rdf.columns.values\n",
    "\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked','women_child']]\n",
    "\n",
    "gender = pd.get_dummies(ndf.sex)\n",
    "ndf = pd.concat([ndf, gender],axis=1)\n",
    "\n",
    "oh_embarked = pd.get_dummies(ndf.embarked, prefix='town')\n",
    "ndf = pd.concat([ndf, oh_embarked], axis=1)\n",
    "ndf = ndf.drop(['embarked','sex'],axis=1,)\n",
    "\n",
    "X = ndf[['pclass','age','sibsp','parch','female','male','town_C','town_Q','town_S','women_child']]\n",
    "y = ndf.survived\n",
    "\n",
    "from sklearn import preprocessing as ppc\n",
    "X = ppc.StandardScaler().fit(X).transform(X)\n",
    "X\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "# 모델 훈련\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "naive_m = BernoulliNB(alpha=0.4)\n",
    "naive_m.fit(X_train, y_train)\n",
    "\n",
    "y_hat = naive_m.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "naive_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "print(naive_matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "print(accuracy)\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(f1_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제227. 현재 라플라스 값이 0.4인데 정확도가 높은 라플라스 값을 찾으시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:19:03.995136Z",
     "start_time": "2020-07-24T06:19:03.250596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state:1\n",
      "0.7574626865671642\n",
      "random_state:2\n",
      "0.7686567164179104\n",
      "random_state:3\n",
      "0.7798507462686567\n",
      "random_state:4\n",
      "0.8171641791044776\n",
      "random_state:5\n",
      "0.7985074626865671\n",
      "random_state:6\n",
      "0.8208955223880597\n",
      "random_state:7\n",
      "0.7425373134328358\n",
      "random_state:8\n",
      "0.7723880597014925\n",
      "random_state:9\n",
      "0.7649253731343284\n",
      "random_state:10\n",
      "0.8097014925373134\n",
      "random_state:11\n",
      "0.8246268656716418\n",
      "random_state:12\n",
      "0.7574626865671642\n",
      "random_state:13\n",
      "0.7798507462686567\n",
      "random_state:14\n",
      "0.8171641791044776\n",
      "random_state:15\n",
      "0.7723880597014925\n",
      "random_state:16\n",
      "0.7873134328358209\n",
      "random_state:17\n",
      "0.753731343283582\n",
      "random_state:18\n",
      "0.7910447761194029\n",
      "random_state:19\n",
      "0.8059701492537313\n",
      "random_state:20\n",
      "0.7873134328358209\n",
      "random_state:21\n",
      "0.7910447761194029\n",
      "random_state:22\n",
      "0.75\n",
      "random_state:23\n",
      "0.7910447761194029\n",
      "random_state:24\n",
      "0.8059701492537313\n",
      "random_state:25\n",
      "0.7761194029850746\n",
      "random_state:26\n",
      "0.7723880597014925\n",
      "random_state:27\n",
      "0.7611940298507462\n",
      "random_state:28\n",
      "0.7723880597014925\n",
      "random_state:29\n",
      "0.7873134328358209\n",
      "random_state:30\n",
      "0.7649253731343284\n",
      "random_state:31\n",
      "0.7835820895522388\n",
      "random_state:32\n",
      "0.7873134328358209\n",
      "random_state:33\n",
      "0.8097014925373134\n",
      "random_state:34\n",
      "0.7947761194029851\n",
      "random_state:35\n",
      "0.7910447761194029\n",
      "random_state:36\n",
      "0.8246268656716418\n",
      "random_state:37\n",
      "0.7910447761194029\n",
      "random_state:38\n",
      "0.8022388059701493\n",
      "random_state:39\n",
      "0.7985074626865671\n",
      "random_state:40\n",
      "0.7910447761194029\n",
      "random_state:41\n",
      "0.8283582089552238\n",
      "random_state:42\n",
      "0.7910447761194029\n",
      "random_state:43\n",
      "0.746268656716418\n",
      "random_state:44\n",
      "0.7611940298507462\n",
      "random_state:45\n",
      "0.8208955223880597\n",
      "random_state:46\n",
      "0.8022388059701493\n",
      "random_state:47\n",
      "0.8097014925373134\n",
      "random_state:48\n",
      "0.7798507462686567\n",
      "random_state:49\n",
      "0.7835820895522388\n",
      "random_state:50\n",
      "0.7873134328358209\n",
      "random_state:51\n",
      "0.7798507462686567\n",
      "random_state:52\n",
      "0.7985074626865671\n",
      "random_state:53\n",
      "0.7835820895522388\n",
      "random_state:54\n",
      "0.7761194029850746\n",
      "random_state:55\n",
      "0.7649253731343284\n",
      "random_state:56\n",
      "0.8619402985074627\n",
      "random_state:57\n",
      "0.7910447761194029\n",
      "random_state:58\n",
      "0.7574626865671642\n",
      "random_state:59\n",
      "0.7574626865671642\n",
      "random_state:60\n",
      "0.7761194029850746\n",
      "random_state:61\n",
      "0.7761194029850746\n",
      "random_state:62\n",
      "0.8022388059701493\n",
      "random_state:63\n",
      "0.7947761194029851\n",
      "random_state:64\n",
      "0.7873134328358209\n",
      "random_state:65\n",
      "0.7947761194029851\n",
      "random_state:66\n",
      "0.7985074626865671\n",
      "random_state:67\n",
      "0.832089552238806\n",
      "random_state:68\n",
      "0.8022388059701493\n",
      "random_state:69\n",
      "0.8059701492537313\n",
      "random_state:70\n",
      "0.8059701492537313\n",
      "random_state:71\n",
      "0.7985074626865671\n",
      "random_state:72\n",
      "0.7761194029850746\n",
      "random_state:73\n",
      "0.7873134328358209\n",
      "random_state:74\n",
      "0.7947761194029851\n",
      "random_state:75\n",
      "0.7649253731343284\n",
      "random_state:76\n",
      "0.8171641791044776\n",
      "random_state:77\n",
      "0.8208955223880597\n",
      "random_state:78\n",
      "0.8283582089552238\n",
      "random_state:79\n",
      "0.7985074626865671\n",
      "random_state:80\n",
      "0.7835820895522388\n",
      "random_state:81\n",
      "0.7649253731343284\n",
      "random_state:82\n",
      "0.7611940298507462\n",
      "random_state:83\n",
      "0.8059701492537313\n",
      "random_state:84\n",
      "0.7350746268656716\n",
      "random_state:85\n",
      "0.7873134328358209\n",
      "random_state:86\n",
      "0.8059701492537313\n",
      "random_state:87\n",
      "0.7873134328358209\n",
      "random_state:88\n",
      "0.7723880597014925\n",
      "random_state:89\n",
      "0.8059701492537313\n",
      "random_state:90\n",
      "0.8022388059701493\n",
      "random_state:91\n",
      "0.7574626865671642\n",
      "random_state:92\n",
      "0.7686567164179104\n",
      "random_state:93\n",
      "0.8059701492537313\n",
      "random_state:94\n",
      "0.8097014925373134\n",
      "random_state:95\n",
      "0.7985074626865671\n",
      "random_state:96\n",
      "0.7761194029850746\n",
      "random_state:97\n",
      "0.7798507462686567\n",
      "random_state:98\n",
      "0.7873134328358209\n",
      "random_state:99\n",
      "0.746268656716418\n",
      "random_state:100\n",
      "0.7835820895522388\n"
     ]
    }
   ],
   "source": [
    "# 예제. 타이타닉 나이브베이즈 모델 생성 예제\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "n_df = pd.read_csv('train.csv')\n",
    "df = pd.concat([df,n_df['Name']],axis=1)\n",
    "appel = df['Name'].str.split(',').str[1].str.split('.')\n",
    "df['title'] = appel.str.get(0)\n",
    "\n",
    "# age_m = pd.DataFrame(round(df.groupby('title')['age'].mean(),1))\n",
    "# df = pd.merge(df, age_m, on='title',how='left')\n",
    "\n",
    "rdf = df.drop(['embark_town','deck'],axis=1)\n",
    "rdf\n",
    "\n",
    "rdf['age'].fillna(rdf['age'].value_counts(dropna=True).idxmax(), inplace=True) # 최빈값으로 치환\n",
    "rdf['embarked'].fillna(rdf['embarked'].value_counts(dropna=True).idxmax() , inplace=True ) \n",
    "\n",
    "mask = (rdf.age<10) | (rdf.sex == 'female')\n",
    "rdf['women_child'] = mask.astype(int)\n",
    "\n",
    "rdf.columns.values\n",
    "\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked','women_child']]\n",
    "\n",
    "gender = pd.get_dummies(ndf.sex)\n",
    "ndf = pd.concat([ndf, gender],axis=1)\n",
    "\n",
    "oh_embarked = pd.get_dummies(ndf.embarked, prefix='town')\n",
    "ndf = pd.concat([ndf, oh_embarked], axis=1)\n",
    "ndf = ndf.drop(['embarked','sex'],axis=1,)\n",
    "\n",
    "X = ndf[['pclass','female','male','town_C','town_Q','town_S','women_child',]]\n",
    "y = ndf.survived\n",
    "\n",
    "from sklearn import preprocessing as ppc\n",
    "X = ppc.StandardScaler().fit(X).transform(X)\n",
    "X\n",
    "\n",
    "for i in range(1,101):\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=i)\n",
    "\n",
    "    # 모델 훈련\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    naive_m = BernoulliNB()\n",
    "    naive_m.fit(X_train, y_train)\n",
    "\n",
    "    y_hat = naive_m.predict(X_test)\n",
    "    naive_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "    accuracy = accuracy_score( y_test, y_hat)\n",
    "\n",
    "    f1_report = metrics.classification_report(y_test, y_hat)\n",
    "    print(f\"random_state:{i}\\n{accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:20:08.852550Z",
     "start_time": "2020-07-24T06:20:08.789590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8619402985074627\n"
     ]
    }
   ],
   "source": [
    "# 예제. 타이타닉 나이브베이즈 모델 생성 예제\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "n_df = pd.read_csv('train.csv')\n",
    "df = pd.concat([df,n_df['Name']],axis=1)\n",
    "appel = df['Name'].str.split(',').str[1].str.split('.')\n",
    "df['title'] = appel.str.get(0)\n",
    "\n",
    "# age_m = pd.DataFrame(round(df.groupby('title')['age'].mean(),1))\n",
    "# df = pd.merge(df, age_m, on='title',how='left')\n",
    "\n",
    "rdf = df.drop(['embark_town','deck'],axis=1)\n",
    "rdf\n",
    "\n",
    "rdf['age'].fillna(rdf['age'].value_counts(dropna=True).idxmax(), inplace=True) # 최빈값으로 치환\n",
    "rdf['embarked'].fillna(rdf['embarked'].value_counts(dropna=True).idxmax() , inplace=True ) \n",
    "\n",
    "mask = (rdf.age<10) | (rdf.sex == 'female')\n",
    "rdf['women_child'] = mask.astype(int)\n",
    "\n",
    "rdf.columns.values\n",
    "\n",
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked','women_child']]\n",
    "\n",
    "gender = pd.get_dummies(ndf.sex)\n",
    "ndf = pd.concat([ndf, gender],axis=1)\n",
    "\n",
    "oh_embarked = pd.get_dummies(ndf.embarked, prefix='town')\n",
    "ndf = pd.concat([ndf, oh_embarked], axis=1)\n",
    "ndf = ndf.drop(['embarked','sex'],axis=1,)\n",
    "\n",
    "X = ndf[['pclass','female','male','town_C','town_Q','town_S','women_child',]]\n",
    "y = ndf.survived\n",
    "\n",
    "from sklearn import preprocessing as ppc\n",
    "X = ppc.StandardScaler().fit(X).transform(X)\n",
    "X\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=56)\n",
    "\n",
    "# 모델 훈련\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "naive_m = BernoulliNB()\n",
    "naive_m.fit(X_train, y_train)\n",
    "\n",
    "y_hat = naive_m.predict(X_test)\n",
    "naive_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ 문제228. seaborn의 타이타닉 말고 Kaggle의 타이타닉을 나이브베이즈 모델을 생성하여 테스트 데이터 예측값을 Kaggle에 올리고 순위를 확인하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:23:43.854280Z",
     "start_time": "2020-07-24T06:23:43.791318Z"
    }
   },
   "outputs": [],
   "source": [
    "# 예제. 타이타닉 나이브베이즈 모델 생성 예제\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "appel = df['Name'].str.split(',').str[1].str.split('.')\n",
    "df['title'] = appel.str.get(0)\n",
    "\n",
    "age_m = pd.DataFrame(round(df.groupby('title')['Age'].mean(),1))\n",
    "df = pd.merge(df, age_m, on='title',how='left')\n",
    "df\n",
    "\n",
    "rdf = df.drop(['Ticket','Cabin'],axis=1)\n",
    "\n",
    "rdf['Age_x'].fillna(rdf['Age_y'].value_counts(dropna=True).idxmax(), inplace=True)\n",
    "# rdf.Age_x.fillna(df.Age_y, inplace=True)# 최빈값으로 치환\n",
    "rdf['Embarked'].fillna(rdf['Embarked'].value_counts(dropna=True).idxmax() , inplace=True ) \n",
    "\n",
    "mask = (rdf.Age_x<10) | (rdf.Sex == 'female')\n",
    "rdf['women_child'] = mask.astype(int)\n",
    "\n",
    "ndf = rdf[['Survived','Pclass','Sex','Age_x','SibSp','Parch','Embarked','women_child']]\n",
    "\n",
    "gender = pd.get_dummies(ndf.Sex)\n",
    "ndf = pd.concat([ndf, gender],axis=1)\n",
    "\n",
    "oh_embarked = pd.get_dummies(ndf.Embarked, prefix='town')\n",
    "ndf = pd.concat([ndf, oh_embarked], axis=1)\n",
    "ndf = ndf.drop(['Embarked','Sex'],axis=1,)\n",
    "ndf.rename(columns={'Age_x':'Age'},inplace=True)\n",
    "\n",
    "X = ndf[['Pclass','female','male','town_C','town_Q','town_S','women_child','Age']]\n",
    "y = ndf.Survived\n",
    "\n",
    "from sklearn import preprocessing as ppc\n",
    "X = ppc.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=56)\n",
    "\n",
    "# 모델 훈련\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "naive_m = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "y_hat = naive_m.predict(X_test)\n",
    "naive_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:36:31.232692Z",
     "start_time": "2020-07-24T06:36:31.176728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df2 = pd.read_csv('test.csv')\n",
    "appel = df2['Name'].str.split(',').str[1].str.split('.')\n",
    "df2['title'] = appel.str.get(0)\n",
    "\n",
    "age_m = pd.DataFrame(round(df2.groupby('title')['Age'].mean(),1))\n",
    "df2 = pd.merge(df2, age_m, on='title',how='left')\n",
    "\n",
    "rdf2 = df2.drop(['Ticket','Cabin'],axis=1)\n",
    "\n",
    "rdf2['Age_x'].fillna(rdf2['Age_y'].value_counts(dropna=True).idxmax(), inplace=True)\n",
    "# rdf.Age_x.fillna(df.Age_y, inplace=True)# 최빈값으로 치환\n",
    "rdf2['Embarked'].fillna(rdf2['Embarked'].value_counts(dropna=True).idxmax() , inplace=True ) \n",
    "\n",
    "mask = (rdf2.Age_x<10) | (rdf2.Sex == 'female')\n",
    "rdf2['women_child'] = mask.astype(int)\n",
    "\n",
    "ndf2 = rdf2[['Survived','Pclass','Sex','Age_x','SibSp','Parch','Embarked','women_child']]\n",
    "\n",
    "gender = pd.get_dummies(ndf2.Sex)\n",
    "ndf2 = pd.concat([ndf2, gender],axis=1)\n",
    "\n",
    "oh_embarked = pd.get_dummies(ndf2.Embarked, prefix='town')\n",
    "ndf = pd.concat([ndf, oh_embarked], axis=1)\n",
    "ndf = ndf.drop(['Embarked','Sex'],axis=1,)\n",
    "ndf.rename(columns={'Age_x':'Age'},inplace=True)\n",
    "\n",
    "X = ndf[['Pclass','female','male','town_C','town_Q','town_S','women_child','Age']]\n",
    "y = ndf.Survived\n",
    "\n",
    "from sklearn import preprocessing as ppc\n",
    "X = ppc.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=56)\n",
    "\n",
    "# 모델 훈련\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "naive_m = BernoulliNB().fit(X_train, y_train)\n",
    "\n",
    "y_hat = naive_m.predict(X_test)\n",
    "naive_matrix = metrics.confusion_matrix(y_test, y_hat)\n",
    "accuracy = accuracy_score( y_test, y_hat)\n",
    "\n",
    "f1_report = metrics.classification_report(y_test, y_hat)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:46:28.502491Z",
     "start_time": "2020-07-24T06:46:28.448526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'child_women'],\n",
      "      dtype='object')\n",
      "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   \n",
      "888         0       3  female   NaN      1      2  23.4500        S   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   \n",
      "\n",
      "     child_women  \n",
      "0              0  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              0  \n",
      "..           ...  \n",
      "886            0  \n",
      "887            1  \n",
      "888            1  \n",
      "889            0  \n",
      "890            0  \n",
      "\n",
      "[891 rows x 9 columns]\n",
      "(891, 9)\n",
      "(891, 9)\n",
      "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   \n",
      "888         0       3  female  24.0      1      2  23.4500        S   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   \n",
      "\n",
      "     child_women  \n",
      "0              0  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              0  \n",
      "..           ...  \n",
      "886            0  \n",
      "887            1  \n",
      "888            1  \n",
      "889            0  \n",
      "890            0  \n",
      "\n",
      "[891 rows x 9 columns]\n",
      "[[ 0.82737724 -0.73769513  0.73769513 ... -0.30756234  0.61583843\n",
      "  -0.79678252]\n",
      " [-1.56610693  1.35557354 -1.35557354 ... -0.30756234 -1.62380254\n",
      "   1.25504761]\n",
      " [ 0.82737724  1.35557354 -1.35557354 ... -0.30756234  0.61583843\n",
      "   1.25504761]\n",
      " ...\n",
      " [ 0.82737724  1.35557354 -1.35557354 ... -0.30756234  0.61583843\n",
      "   1.25504761]\n",
      " [-1.56610693 -0.73769513  0.73769513 ... -0.30756234 -1.62380254\n",
      "  -0.79678252]\n",
      " [ 0.82737724 -0.73769513  0.73769513 ...  3.25137334 -1.62380254\n",
      "  -0.79678252]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "# 1단계 csv ---> 데이터 프레임으로 변환\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "pd.set_option('display.max_columns',15)\n",
    "\n",
    "mask4 = (df.Age<10) | (df.Sex=='female') \n",
    "df['child_women']=mask4.astype(int)\n",
    "\n",
    "print ( df.columns)\n",
    "\n",
    "# 2.2 결측치(NaN) 을 확인한다.\n",
    "# 2.3 deck 컬럼과 embark_town 컬럼을 삭제한다.\n",
    "# 설명 : deck 결측치가 많아서 컬럼을 삭제해야함.\n",
    "# embark 와 embark_town 이 같은 데이터여서 embark 컬럼을 삭제해야함\n",
    "\n",
    "rdf = df.drop(['PassengerId','Cabin','Name','Ticket'], axis =1)\n",
    "print(rdf)\n",
    "\n",
    "# 2.4 age(나이) 열에 나이가 없는 모든행을 삭제한다.\n",
    "# 데이터가 한개라도 없으면 drop 해라 (how = 'any')\n",
    "# 모든 데이터가 없으면 drop 해라 (how = 'all')\n",
    "\n",
    "print(rdf.shape)\n",
    "\n",
    "# 나이의 결측치를 최빈값으로 치환\n",
    "most_freq = rdf['Age'].value_counts(dropna=True).idxmax()  \n",
    "rdf['Age'].fillna(most_freq, inplace=True)\n",
    "print(rdf.shape)\n",
    "\n",
    "# 2.5 embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "most_freq = rdf['Embarked'].value_counts().idxmax()\n",
    "rdf['Embarked'].fillna(most_freq, inplace = True)\n",
    "print(rdf)\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "ndf = rdf[['Survived','Pclass','Sex','Age','SibSp','Parch','Embarked','child_women']]\n",
    "ndf = rdf\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "#3.2 범주형 데이터를 숫자로 변환하기(원핫 인코딩)\n",
    "\n",
    "gender = pd.get_dummies(ndf['Sex'])\n",
    "ndf = pd.concat([ndf,gender], axis= 1)\n",
    "onehot_embarked = pd.get_dummies(ndf['Embarked'])\n",
    "ndf = pd.concat([ndf,onehot_embarked],axis=1)\n",
    "ndf.drop(['Sex','Embarked'], axis=1, inplace = True)\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "x = ndf[ ['Pclass', 'Age' ,'SibSp', 'Parch' ,'female' ,'male', 'C' ,'Q' ,'S',\n",
    "          'child_women'] ]\n",
    "\n",
    "y = ndf['Survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(x).transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-24T06:55:53.998151Z",
     "start_time": "2020-07-24T06:55:53.902210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "892 , 0\n",
      "893 , 1\n",
      "894 , 0\n",
      "895 , 0\n",
      "896 , 1\n",
      "897 , 0\n",
      "898 , 1\n",
      "899 , 0\n",
      "900 , 1\n",
      "901 , 0\n",
      "902 , 0\n",
      "903 , 0\n",
      "904 , 1\n",
      "905 , 0\n",
      "906 , 1\n",
      "907 , 1\n",
      "908 , 0\n",
      "909 , 0\n",
      "910 , 1\n",
      "911 , 1\n",
      "912 , 0\n",
      "913 , 0\n",
      "914 , 1\n",
      "915 , 0\n",
      "916 , 1\n",
      "917 , 0\n",
      "918 , 1\n",
      "919 , 0\n",
      "920 , 0\n",
      "921 , 0\n",
      "922 , 0\n",
      "923 , 0\n",
      "924 , 1\n",
      "925 , 1\n",
      "926 , 0\n",
      "927 , 0\n",
      "928 , 1\n",
      "929 , 1\n",
      "930 , 0\n",
      "931 , 0\n",
      "932 , 0\n",
      "933 , 0\n",
      "934 , 0\n",
      "935 , 1\n",
      "936 , 1\n",
      "937 , 0\n",
      "938 , 0\n",
      "939 , 0\n",
      "940 , 1\n",
      "941 , 1\n",
      "942 , 0\n",
      "943 , 0\n",
      "944 , 1\n",
      "945 , 1\n",
      "946 , 0\n",
      "947 , 0\n",
      "948 , 0\n",
      "949 , 0\n",
      "950 , 0\n",
      "951 , 1\n",
      "952 , 0\n",
      "953 , 0\n",
      "954 , 0\n",
      "955 , 1\n",
      "956 , 0\n",
      "957 , 1\n",
      "958 , 1\n",
      "959 , 0\n",
      "960 , 0\n",
      "961 , 1\n",
      "962 , 1\n",
      "963 , 0\n",
      "964 , 1\n",
      "965 , 0\n",
      "966 , 1\n",
      "967 , 0\n",
      "968 , 0\n",
      "969 , 1\n",
      "970 , 0\n",
      "971 , 1\n",
      "972 , 1\n",
      "973 , 0\n",
      "974 , 0\n",
      "975 , 0\n",
      "976 , 0\n",
      "977 , 0\n",
      "978 , 1\n",
      "979 , 1\n",
      "980 , 1\n",
      "981 , 1\n",
      "982 , 1\n",
      "983 , 0\n",
      "984 , 1\n",
      "985 , 0\n",
      "986 , 0\n",
      "987 , 0\n",
      "988 , 1\n",
      "989 , 0\n",
      "990 , 1\n",
      "991 , 0\n",
      "992 , 1\n",
      "993 , 0\n",
      "994 , 0\n",
      "995 , 0\n",
      "996 , 1\n",
      "997 , 0\n",
      "998 , 0\n",
      "999 , 0\n",
      "1000 , 0\n",
      "1001 , 0\n",
      "1002 , 0\n",
      "1003 , 1\n",
      "1004 , 1\n",
      "1005 , 1\n",
      "1006 , 1\n",
      "1007 , 0\n",
      "1008 , 0\n",
      "1009 , 1\n",
      "1010 , 0\n",
      "1011 , 1\n",
      "1012 , 1\n",
      "1013 , 0\n",
      "1014 , 1\n",
      "1015 , 0\n",
      "1016 , 0\n",
      "1017 , 1\n",
      "1018 , 0\n",
      "1019 , 1\n",
      "1020 , 0\n",
      "1021 , 0\n",
      "1022 , 0\n",
      "1023 , 0\n",
      "1024 , 1\n",
      "1025 , 0\n",
      "1026 , 0\n",
      "1027 , 0\n",
      "1028 , 0\n",
      "1029 , 0\n",
      "1030 , 1\n",
      "1031 , 0\n",
      "1032 , 1\n",
      "1033 , 1\n",
      "1034 , 0\n",
      "1035 , 0\n",
      "1036 , 0\n",
      "1037 , 0\n",
      "1038 , 0\n",
      "1039 , 0\n",
      "1040 , 0\n",
      "1041 , 0\n",
      "1042 , 1\n",
      "1043 , 0\n",
      "1044 , 0\n",
      "1045 , 1\n",
      "1046 , 0\n",
      "1047 , 0\n",
      "1048 , 1\n",
      "1049 , 1\n",
      "1050 , 0\n",
      "1051 , 1\n",
      "1052 , 1\n",
      "1053 , 1\n",
      "1054 , 1\n",
      "1055 , 0\n",
      "1056 , 0\n",
      "1057 , 1\n",
      "1058 , 0\n",
      "1059 , 0\n",
      "1060 , 1\n",
      "1061 , 1\n",
      "1062 , 0\n",
      "1063 , 0\n",
      "1064 , 0\n",
      "1065 , 0\n",
      "1066 , 0\n",
      "1067 , 1\n",
      "1068 , 1\n",
      "1069 , 0\n",
      "1070 , 1\n",
      "1071 , 1\n",
      "1072 , 0\n",
      "1073 , 0\n",
      "1074 , 1\n",
      "1075 , 0\n",
      "1076 , 1\n",
      "1077 , 0\n",
      "1078 , 1\n",
      "1079 , 0\n",
      "1080 , 1\n",
      "1081 , 0\n",
      "1082 , 0\n",
      "1083 , 0\n",
      "1084 , 0\n",
      "1085 , 0\n",
      "1086 , 0\n",
      "1087 , 0\n",
      "1088 , 1\n",
      "1089 , 1\n",
      "1090 , 0\n",
      "1091 , 1\n",
      "1092 , 1\n",
      "1093 , 0\n",
      "1094 , 0\n",
      "1095 , 1\n",
      "1096 , 0\n",
      "1097 , 0\n",
      "1098 , 1\n",
      "1099 , 0\n",
      "1100 , 1\n",
      "1101 , 0\n",
      "1102 , 0\n",
      "1103 , 0\n",
      "1104 , 0\n",
      "1105 , 1\n",
      "1106 , 1\n",
      "1107 , 0\n",
      "1108 , 1\n",
      "1109 , 0\n",
      "1110 , 1\n",
      "1111 , 0\n",
      "1112 , 1\n",
      "1113 , 0\n",
      "1114 , 1\n",
      "1115 , 0\n",
      "1116 , 1\n",
      "1117 , 1\n",
      "1118 , 0\n",
      "1119 , 1\n",
      "1120 , 0\n",
      "1121 , 0\n",
      "1122 , 0\n",
      "1123 , 1\n",
      "1124 , 0\n",
      "1125 , 0\n",
      "1126 , 0\n",
      "1127 , 0\n",
      "1128 , 0\n",
      "1129 , 0\n",
      "1130 , 1\n",
      "1131 , 1\n",
      "1132 , 1\n",
      "1133 , 1\n",
      "1134 , 0\n",
      "1135 , 0\n",
      "1136 , 0\n",
      "1137 , 0\n",
      "1138 , 1\n",
      "1139 , 0\n",
      "1140 , 1\n",
      "1141 , 1\n",
      "1142 , 1\n",
      "1143 , 0\n",
      "1144 , 0\n",
      "1145 , 0\n",
      "1146 , 0\n",
      "1147 , 0\n",
      "1148 , 0\n",
      "1149 , 0\n",
      "1150 , 1\n",
      "1151 , 0\n",
      "1152 , 0\n",
      "1153 , 0\n",
      "1154 , 1\n",
      "1155 , 1\n",
      "1156 , 0\n",
      "1157 , 0\n",
      "1158 , 0\n",
      "1159 , 0\n",
      "1160 , 1\n",
      "1161 , 0\n",
      "1162 , 0\n",
      "1163 , 0\n",
      "1164 , 1\n",
      "1165 , 1\n",
      "1166 , 0\n",
      "1167 , 1\n",
      "1168 , 0\n",
      "1169 , 0\n",
      "1170 , 0\n",
      "1171 , 0\n",
      "1172 , 1\n",
      "1173 , 0\n",
      "1174 , 1\n",
      "1175 , 1\n",
      "1176 , 1\n",
      "1177 , 0\n",
      "1178 , 0\n",
      "1179 , 0\n",
      "1180 , 0\n",
      "1181 , 0\n",
      "1182 , 0\n",
      "1183 , 1\n",
      "1184 , 0\n",
      "1185 , 0\n",
      "1186 , 0\n",
      "1187 , 0\n",
      "1188 , 1\n",
      "1189 , 0\n",
      "1190 , 0\n",
      "1191 , 0\n",
      "1192 , 0\n",
      "1193 , 0\n",
      "1194 , 0\n",
      "1195 , 0\n",
      "1196 , 1\n",
      "1197 , 1\n",
      "1198 , 0\n",
      "1199 , 0\n",
      "1200 , 0\n",
      "1201 , 1\n",
      "1202 , 0\n",
      "1203 , 0\n",
      "1204 , 0\n",
      "1205 , 1\n",
      "1206 , 1\n",
      "1207 , 1\n",
      "1208 , 0\n",
      "1209 , 0\n",
      "1210 , 0\n",
      "1211 , 0\n",
      "1212 , 0\n",
      "1213 , 0\n",
      "1214 , 0\n",
      "1215 , 0\n",
      "1216 , 1\n",
      "1217 , 0\n",
      "1218 , 1\n",
      "1219 , 0\n",
      "1220 , 0\n",
      "1221 , 0\n",
      "1222 , 1\n",
      "1223 , 0\n",
      "1224 , 0\n",
      "1225 , 1\n",
      "1226 , 0\n",
      "1227 , 0\n",
      "1228 , 0\n",
      "1229 , 0\n",
      "1230 , 0\n",
      "1231 , 0\n",
      "1232 , 0\n",
      "1233 , 0\n",
      "1234 , 0\n",
      "1235 , 1\n",
      "1236 , 0\n",
      "1237 , 1\n",
      "1238 , 0\n",
      "1239 , 1\n",
      "1240 , 0\n",
      "1241 , 1\n",
      "1242 , 1\n",
      "1243 , 0\n",
      "1244 , 0\n",
      "1245 , 0\n",
      "1246 , 1\n",
      "1247 , 0\n",
      "1248 , 1\n",
      "1249 , 0\n",
      "1250 , 0\n",
      "1251 , 1\n",
      "1252 , 0\n",
      "1253 , 1\n",
      "1254 , 1\n",
      "1255 , 0\n",
      "1256 , 1\n",
      "1257 , 1\n",
      "1258 , 0\n",
      "1259 , 1\n",
      "1260 , 1\n",
      "1261 , 0\n",
      "1262 , 0\n",
      "1263 , 1\n",
      "1264 , 0\n",
      "1265 , 0\n",
      "1266 , 1\n",
      "1267 , 1\n",
      "1268 , 1\n",
      "1269 , 0\n",
      "1270 , 0\n",
      "1271 , 0\n",
      "1272 , 0\n",
      "1273 , 0\n",
      "1274 , 1\n",
      "1275 , 1\n",
      "1276 , 0\n",
      "1277 , 1\n",
      "1278 , 0\n",
      "1279 , 0\n",
      "1280 , 0\n",
      "1281 , 0\n",
      "1282 , 0\n",
      "1283 , 1\n",
      "1284 , 0\n",
      "1285 , 0\n",
      "1286 , 0\n",
      "1287 , 1\n",
      "1288 , 0\n",
      "1289 , 1\n",
      "1290 , 0\n",
      "1291 , 0\n",
      "1292 , 1\n",
      "1293 , 0\n",
      "1294 , 1\n",
      "1295 , 0\n",
      "1296 , 0\n",
      "1297 , 0\n",
      "1298 , 0\n",
      "1299 , 0\n",
      "1300 , 1\n",
      "1301 , 1\n",
      "1302 , 1\n",
      "1303 , 1\n",
      "1304 , 1\n",
      "1305 , 0\n",
      "1306 , 1\n",
      "1307 , 0\n",
      "1308 , 0\n",
      "1309 , 0\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터도 훈련 데이터와 같이 데이터를 구성한다.\n",
    "x_ktest = pd.read_csv(\"test.csv\")\n",
    "mask4 = (x_ktest.Age<10) | (x_ktest.Sex=='female') \n",
    "x_ktest['child_women']=mask4.astype(int)\n",
    "\n",
    "rdf_x_ktest = x_ktest.drop(['PassengerId','Cabin','Name','Ticket'], axis =1)\n",
    "\n",
    "most_freq = rdf_x_ktest['Age'].value_counts(dropna=True).idxmax()  # 나이의 결측치를 최빈값으로 치환\n",
    "rdf_x_ktest['Age'].fillna(most_freq, inplace=True)\n",
    "\n",
    "most_freq = rdf_x_ktest['Embarked'].value_counts().idxmax() # embark 열의 NaN 값을 승선도시중 가장 많이 출현한 값으로 치환하기\n",
    "rdf_x_ktest['Embarked'].fillna(most_freq, inplace = True)\n",
    "\n",
    "# 3단계 범주형 데이터를 숫자형으로 변환하기\n",
    "# 3.1 feature selection (분석에 필요한 속성을 선택)\n",
    "#ndf_x_ktest = rdf_x_ktest[['Survived','Pclass','Sex','Age','Sibsp','Parch','Embarked','child_women']]\n",
    "ndf_x_ktest = rdf_x_ktest\n",
    "\n",
    "# 선택된 컬럼중 2개(sex, embarked) 가 범주형이다.\n",
    "gender = pd.get_dummies(ndf_x_ktest['Sex'])\n",
    "ndf_x_ktest = pd.concat([ndf_x_ktest,gender], axis= 1)\n",
    "onehot_embarked = pd.get_dummies(ndf_x_ktest['Embarked'])\n",
    "ndf_x_ktest = pd.concat([ndf_x_ktest,onehot_embarked],axis=1)\n",
    "ndf_x_ktest.drop(['Sex','Embarked'], axis=1, inplace = True)\n",
    "\n",
    "# 4단계 정규화\n",
    "# 4.1 독립변수와 종속변수(라벨) 을 지정한다.\n",
    "# survived  pclass   age  sibsp  parch  female  male  C  Q  S\n",
    "#   라벨                       데이터\n",
    "# 종속변수                     독립변수\n",
    "x = ndf_x_ktest[ ['Pclass', 'Age' ,'SibSp', 'Parch' ,'female' ,'male', 'C' ,'Q' ,'S', 'child_women'] ]\n",
    "#y = ndf_x_ktest['Survived'] # 종속변수\n",
    "\n",
    "# 4.2 독립변수들을 정규화 한다.\n",
    "from sklearn import preprocessing\n",
    "X_test = preprocessing.StandardScaler().fit(x).transform(x)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "model = BernoulliNB( alpha = 0.4 )\n",
    "model.fit( X, y )\n",
    "y_hat = model.predict( X_test )\n",
    "\n",
    "# Kaggle에 올리기 위한 포맷으로 데이터를 구성한다.\n",
    "for  i,a  in  enumerate(y_hat):\n",
    "    print (i+892,',',a)\n",
    "\n",
    "# # 8단계 모형의 예측능력을 평가한다.\n",
    "\n",
    "# from sklearn import metrics\n",
    "# knn_matrix = metrics.confusion_matrix( y_test, y_hat )\n",
    "# print( knn_matrix )\n",
    "\n",
    "# tn, fp, fn, tp = metrics.confusion_matrix( y_test, y_hat ).ravel\n",
    "# f1_report = metrics.classification_report( y_test, y_hat )\n",
    "# print( f1_report )\n",
    "\n",
    "# #print(np.array([[tp,fp],[fn,tn]]))\n",
    "\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy = accuracy_score( y_test, y_hat)\n",
    "# print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
